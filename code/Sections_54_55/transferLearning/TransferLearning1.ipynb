{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.nets\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train_dir', default='coco-animals/train')\n",
    "parser.add_argument('--val_dir', default='coco-animals/val')\n",
    "parser.add_argument('--model_path', default='vgg_16.ckpt', type=str)\n",
    "parser.add_argument('--batch_size', default=32, type=int)\n",
    "parser.add_argument('--num_workers', default=4, type=int)\n",
    "parser.add_argument('--num_epochs1', default=10, type=int)\n",
    "parser.add_argument('--num_epochs2', default=10, type=int)\n",
    "parser.add_argument('--learning_rate1', default=1e-3, type=float)\n",
    "parser.add_argument('--learning_rate2', default=1e-5, type=float)\n",
    "parser.add_argument('--dropout_keep_prob', default=0.5, type=float)\n",
    "parser.add_argument('--weight_decay', default=5e-4, type=float)\n",
    "\n",
    "VGG_MEAN = [123.68, 116.78, 103.94]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_images(directory):\n",
    "    \"\"\"\n",
    "    Get all the images and labels in directory/label/*.jpg\n",
    "    \"\"\"\n",
    "    labels = os.listdir(directory)\n",
    "    files_and_labels = []\n",
    "    for label in labels:\n",
    "        for f in os.listdir(os.path.join(directory, label)):\n",
    "            files_and_labels.append((os.path.join(directory, label, f), label))\n",
    "\n",
    "    filenames, labels = zip(*files_and_labels)\n",
    "    filenames = list(filenames)\n",
    "    labels = list(labels)\n",
    "    unique_labels = list(set(labels))\n",
    "\n",
    "    label_to_int = {}\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        label_to_int[label] = i\n",
    "\n",
    "    labels = [label_to_int[l] for l in labels]\n",
    "\n",
    "    return filenames, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def check_accuracy(sess, correct_prediction, is_training, dataset_init_op):\n",
    "    \"\"\"\n",
    "    Check the accuracy of the model on either train or val (depending on dataset_init_op).\n",
    "    \"\"\"\n",
    "    # Initialize the correct dataset\n",
    "    sess.run(dataset_init_op)\n",
    "    num_correct, num_samples = 0, 0\n",
    "    while True:\n",
    "        try:\n",
    "            correct_pred = sess.run(correct_prediction, {is_training: False})\n",
    "            num_correct += correct_pred.sum()\n",
    "            num_samples += correct_pred.shape[0]\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            break\n",
    "\n",
    "    # Return the fraction of datapoints that were correctly classified\n",
    "    acc = float(num_correct) / num_samples\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    # Get the list of filenames and corresponding list of labels for training et validation\n",
    "    train_filenames, train_labels = list_images(args.train_dir)\n",
    "    val_filenames, val_labels = list_images(args.val_dir)\n",
    "\n",
    "    num_classes = len(set(train_labels))\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # In TensorFlow, you first want to define the computation graph with all the\n",
    "    # necessary operations: loss, training op, accuracy...\n",
    "    # Any tensor created in the `graph.as_default()` scope will be part of `graph`\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        # Standard preprocessing for VGG on ImageNet taken from here:\n",
    "        # https://github.com/tensorflow/models/blob/master/slim/preprocessing/vgg_preprocessing.py\n",
    "        # Also see the VGG paper for more details: https://arxiv.org/pdf/1409.1556.pdf\n",
    "\n",
    "        # Preprocessing (for both training and validation):\n",
    "        # (1) Decode the image from jpg format\n",
    "        # (2) Resize the image so its smaller side is 256 pixels long\n",
    "        def _parse_function(filename, label):\n",
    "            image_string = tf.read_file(filename)\n",
    "            image_decoded = tf.image.decode_jpeg(image_string, channels=3)          # (1)\n",
    "            image = tf.cast(image_decoded, tf.float32)\n",
    "\n",
    "            smallest_side = 256.0\n",
    "            height, width = tf.shape(image)[0], tf.shape(image)[1]\n",
    "            height = tf.to_float(height)\n",
    "            width = tf.to_float(width)\n",
    "\n",
    "            scale = tf.cond(tf.greater(height, width),\n",
    "                            lambda: smallest_side / width,\n",
    "                            lambda: smallest_side / height)\n",
    "            new_height = tf.to_int32(height * scale)\n",
    "            new_width = tf.to_int32(width * scale)\n",
    "\n",
    "            resized_image = tf.image.resize_images(image, [new_height, new_width])  # (2)\n",
    "            return resized_image, label\n",
    "\n",
    "        # Preprocessing (for training)\n",
    "        # (3) Take a random 224x224 crop to the scaled image\n",
    "        # (4) Horizontally flip the image with probability 1/2\n",
    "        # (5) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def training_preprocess(image, label):\n",
    "            crop_image = tf.random_crop(image, [224, 224, 3])                       # (3)\n",
    "            flip_image = tf.image.random_flip_left_right(crop_image)                # (4)\n",
    "\n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = flip_image - means                                     # (5)\n",
    "\n",
    "            return centered_image, label\n",
    "\n",
    "        # Preprocessing (for validation)\n",
    "        # (3) Take a central 224x224 crop to the scaled image\n",
    "        # (4) Substract the per color mean `VGG_MEAN`\n",
    "        # Note: we don't normalize the data here, as VGG was trained without normalization\n",
    "        def val_preprocess(image, label):\n",
    "            crop_image = tf.image.resize_image_with_crop_or_pad(image, 224, 224)    # (3)\n",
    "\n",
    "            means = tf.reshape(tf.constant(VGG_MEAN), [1, 1, 3])\n",
    "            centered_image = crop_image - means                                     # (4)\n",
    "\n",
    "            return centered_image, label\n",
    "\n",
    "        # ----------------------------------------------------------------------\n",
    "        # DATASET CREATION using tf.contrib.data.Dataset\n",
    "        # https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data\n",
    "\n",
    "        # The tf.contrib.data.Dataset framework uses queues in the background to feed in\n",
    "        # data to the model.\n",
    "        # We initialize the dataset with a list of filenames and labels, and then apply\n",
    "        # the preprocessing functions described above.\n",
    "        # Behind the scenes, queues will load the filenames, preprocess them with multiple\n",
    "        # threads and apply the preprocessing in parallel, and then batch the data\n",
    "\n",
    "        # Training dataset\n",
    "        train_filenames = tf.constant(train_filenames)\n",
    "        train_labels = tf.constant(train_labels)\n",
    "        train_dataset = tf.contrib.data.Dataset.from_tensor_slices((train_filenames, train_labels))\n",
    "        train_dataset = train_dataset.map(_parse_function,\n",
    "            num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.map(training_preprocess,\n",
    "            num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        train_dataset = train_dataset.shuffle(buffer_size=10000)  # don't forget to shuffle\n",
    "        batched_train_dataset = train_dataset.batch(args.batch_size)\n",
    "\n",
    "        # Validation dataset\n",
    "        val_filenames = tf.constant(val_filenames)\n",
    "        val_labels = tf.constant(val_labels)\n",
    "        val_dataset = tf.contrib.data.Dataset.from_tensor_slices((val_filenames, val_labels))\n",
    "        val_dataset = val_dataset.map(_parse_function,\n",
    "            num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        val_dataset = val_dataset.map(val_preprocess,\n",
    "            num_threads=args.num_workers, output_buffer_size=args.batch_size)\n",
    "        batched_val_dataset = val_dataset.batch(args.batch_size)\n",
    "\n",
    "\n",
    "        # Now we define an iterator that can operator on either dataset.\n",
    "        # The iterator can be reinitialized by calling:\n",
    "        #     - sess.run(train_init_op) for 1 epoch on the training set\n",
    "        #     - sess.run(val_init_op)   for 1 epoch on the valiation set\n",
    "        # Once this is done, we don't need to feed any value for images and labels\n",
    "        # as they are automatically pulled out from the iterator queues.\n",
    "\n",
    "        # A reinitializable iterator is defined by its structure. We could use the\n",
    "        # `output_types` and `output_shapes` properties of either `train_dataset`\n",
    "        # or `validation_dataset` here, because they are compatible.\n",
    "        iterator = tf.contrib.data.Iterator.from_structure(batched_train_dataset.output_types,\n",
    "                                                           batched_train_dataset.output_shapes)\n",
    "        images, labels = iterator.get_next()\n",
    "\n",
    "        train_init_op = iterator.make_initializer(batched_train_dataset)\n",
    "        val_init_op = iterator.make_initializer(batched_val_dataset)\n",
    "\n",
    "        # Indicates whether we are in training or in test mode\n",
    "        is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Now that we have set up the data, it's time to set up the model.\n",
    "        # For this example, we'll use VGG-16 pretrained on ImageNet. We will remove the\n",
    "        # last fully connected layer (fc8) and replace it with our own, with an\n",
    "        # output size num_classes=8\n",
    "        # We will first train the last layer for a few epochs.\n",
    "        # Then we will train the entire model on our dataset for a few epochs.\n",
    "\n",
    "        # Get the pretrained model, specifying the num_classes argument to create a new\n",
    "        # fully connected replacing the last one, called \"vgg_16/fc8\"\n",
    "        # Each model has a different architecture, so \"vgg_16/fc8\" will change in another model.\n",
    "        # Here, logits gives us directly the predicted scores we wanted from the images.\n",
    "        # We pass a scope to initialize \"vgg_16/fc8\" weights with he_initializer\n",
    "        vgg = tf.contrib.slim.nets.vgg\n",
    "        with slim.arg_scope(vgg.vgg_arg_scope(weight_decay=args.weight_decay)):\n",
    "            logits, _ = vgg.vgg_16(images, num_classes=num_classes, is_training=is_training,\n",
    "                                   dropout_keep_prob=args.dropout_keep_prob)\n",
    "\n",
    "        # Specify where the model checkpoint is (pretrained weights).\n",
    "        model_path = args.model_path\n",
    "        assert(os.path.isfile(model_path))\n",
    "\n",
    "        # Restore only the layers up to fc7 (included)\n",
    "        # Calling function `init_fn(sess)` will load all the pretrained weights.\n",
    "        variables_to_restore = tf.contrib.framework.get_variables_to_restore(exclude=['vgg_16/fc8'])\n",
    "        init_fn = tf.contrib.framework.assign_from_checkpoint_fn(model_path, variables_to_restore)\n",
    "\n",
    "        # Initialization operation from scratch for the new \"fc8\" layers\n",
    "        # `get_variables` will only return the variables whose name starts with the given pattern\n",
    "        fc8_variables = tf.contrib.framework.get_variables('vgg_16/fc8')\n",
    "        fc8_init = tf.variables_initializer(fc8_variables)\n",
    "\n",
    "        # ---------------------------------------------------------------------\n",
    "        # Using tf.losses, any loss is added to the tf.GraphKeys.LOSSES collection\n",
    "        # We can then call the total loss easily\n",
    "        tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "        loss = tf.losses.get_total_loss()\n",
    "\n",
    "        # First we want to train only the reinitialized last layer fc8 for a few epochs.\n",
    "        # We run minimize the loss only with respect to the fc8 variables (weight and bias).\n",
    "        fc8_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate1)\n",
    "        fc8_train_op = fc8_optimizer.minimize(loss, var_list=fc8_variables)\n",
    "\n",
    "        # Then we want to finetune the entire model for a few epochs.\n",
    "        # We run minimize the loss only with respect to all the variables.\n",
    "        full_optimizer = tf.train.GradientDescentOptimizer(args.learning_rate2)\n",
    "        full_train_op = full_optimizer.minimize(loss)\n",
    "\n",
    "        # Evaluation metrics\n",
    "        prediction = tf.to_int32(tf.argmax(logits, 1))\n",
    "        correct_prediction = tf.equal(prediction, labels)\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "        tf.get_default_graph().finalize()\n",
    "\n",
    "    # --------------------------------------------------------------------------\n",
    "    # Now that we have built the graph and finalized it, we define the session.\n",
    "    # The session is the interface to *run* the computational graph.\n",
    "    # We can call our training operations with `sess.run(train_op)` for instance\n",
    "    with tf.Session(graph=graph) as sess:\n",
    "        init_fn(sess)  # load the pretrained weights\n",
    "        sess.run(fc8_init)  # initialize the new fc8 layer\n",
    "\n",
    "        # Update only the last layer for a few epochs.\n",
    "        for epoch in range(args.num_epochs1):\n",
    "            # Run an epoch over the training data.\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs1))\n",
    "            # Here we initialize the iterator with the training set.\n",
    "            # This means that we can go through an entire epoch until the iterator becomes empty.\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _ = sess.run(fc8_train_op, {is_training: True})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "\n",
    "            # Check accuracy on the train and val sets every epoch.\n",
    "            train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            print('Train accuracy: %f' % train_acc)\n",
    "            print('Val accuracy: %f\\n' % val_acc)\n",
    "\n",
    "\n",
    "        # Train the entire model for a few more epochs, continuing with the *same* weights.\n",
    "        for epoch in range(args.num_epochs2):\n",
    "            print('Starting epoch %d / %d' % (epoch + 1, args.num_epochs1))\n",
    "            sess.run(train_init_op)\n",
    "            while True:\n",
    "                try:\n",
    "                    _ = sess.run(full_train_op, {is_training: True})\n",
    "                except tf.errors.OutOfRangeError:\n",
    "                    break\n",
    "\n",
    "            # Check accuracy on the train and val sets every epoch\n",
    "            train_acc = check_accuracy(sess, correct_prediction, is_training, train_init_op)\n",
    "            val_acc = check_accuracy(sess, correct_prediction, is_training, val_init_op)\n",
    "            print('Train accuracy: %f' % train_acc)\n",
    "            print('Val accuracy: %f\\n' % val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: __main__.py [-h] [--train_dir TRAIN_DIR] [--val_dir VAL_DIR]\n",
      "                   [--model_path MODEL_PATH] [--batch_size BATCH_SIZE]\n",
      "                   [--num_workers NUM_WORKERS] [--num_epochs1 NUM_EPOCHS1]\n",
      "                   [--num_epochs2 NUM_EPOCHS2]\n",
      "                   [--learning_rate1 LEARNING_RATE1]\n",
      "                   [--learning_rate2 LEARNING_RATE2]\n",
      "                   [--dropout_keep_prob DROPOUT_KEEP_PROB]\n",
      "                   [--weight_decay WEIGHT_DECAY]\n",
      "__main__.py: error: unrecognized arguments: -f /run/user/1002/jupyter/kernel-13d34577-8c39-426b-9439-f1456b55b0be.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To exit: use 'exit', 'quit', or Ctrl-D.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    args = parser.parse_args()\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
